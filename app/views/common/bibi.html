<div class="container-with-navbar-margin container-fluid">
  <h2>Brain Interfaces & Body Integrator</h2>
  <h4><span class="label label-warning">The Brain Interfaces & Body Integrator development will start soon.</span></h4>

  <p>One of the biggest challenges for neurorobotics experiments is the coupling between brain models and the various
    sensors and effectors of a robot. In the Neurorobotics Platform, this task is solved by the Brain Interfaces and
    Body Integrator (BIBI). The BIBI will let the user choose a brain simulator
    and a brain model to run on it, and then it will let the user connect it to a virtual robot. These connections are
    then used during the simulation to transfer data from the sensors of the virtual robot to the desired parts of the
    brain model and from the brain model back to the actuators of the virtual robot.
  </p>

  <p>BIBI is used to specify the connections
    between brain model and robot during design time. During the simulation, the Closed-Loop Engine is responsible for
    transferring the respective data between the brain simulation engine (e.g. NETSIM) and the World Simulation Engine.
    So-called transfer functions offer the user a programmatic framework to transform the data that is exchanged between
    brain and robot model (see SP 10 specification document). For example, transfer functions are the way to translate
    spikes and current coming from a neural simulation into the physical signals for robot servo-motors or activation
    signals for abstract muscle models.</p>

  <h4>Meanwhile...</h4>

  <p>The platform supports <a href="http://neuralensemble.org/PyNN/">PyNN</a>
    (<img
      src="img/common/pynn-logo.png" alt="PyNN"/>) as interface to the neuronal simulator. Behind PyNN,
    we are currently using <a href="http://nest-initiative.org/">NEST</a> (<img
    src="img/common/nest-logo.png" alt="NEST"/>) as simulation backend.</p>

  <p>The transfer functions describe how spikes from the neuronal simulation are to be translated into commands for a
    robot and how the sensor data from the robot should be translated back to spikes. This translation is specified by
    the users of the Neurorobotics project, which are neuroscientists. Thus, a framework is provided to make the
    specification of these transfer functions as easy as possible for the users and abstracting away technical details
    as much as possible. This framework is referred to as Transfer Functions framework (TF framework).</p>

  <p>Here is a python example of a transfer function.</p>

  <textarea ui-codemirror="{
            lineWrapping : true,
            lineNumbers: true,
            mode: 'text/x-python',
            readOnly: true
        }">import hbp_nrp_cle.tf_framework as nrp
import geometry_msgs.msg

@nrp.MapSpikeSink("left_wheel_neuron", nrp.brain.actors[1], nrp.leaky_integrator_alpha)
@nrp.MapSpikeSink("right_wheel_neuron", nrp.brain.actors[2], nrp.leaky_integrator_alpha)
@nrp.Neuron2Robot(Topic('/husky/cmd_vel', geometry_msgs.msg.Twist))
def linear_twist(t, left_wheel_neuron, right_wheel_neuron):
    linear = geometry_msgs.msg.Vector3(x=20.0 * min(left_wheel_neuron.voltage, right_wheel_neuron.voltage), y=0.0, z=0.0)
    angular = geometry_msgs.msg.Vector3(x=0.0, y=0.0, z=100.0 * (right_wheel_neuron.voltage - left_wheel_neuron.voltage))
    return geometry_msgs.msg.Twist(linear=linear, angular=angular)</textarea>

    <p>The first line of the above short listing simply imports the TF framework into the current script. Below that in lines 4-10 is an example of a transfer
      function translating the voltage of actor neurons into robot commands. This is done by a Python function with a set
      of decorators. The most important decorator is <i>@nrp.Neuron2Robot</i> in line 6 which marks the function as a transfer function
      from the neuronal network towards the robot and automatically registers it. Furthermore, the decorator specifies what the platform should do with the functions
      return value. In the example, the return value is sent to the robot on the topic <i>/husky/cmd_vel</i>. The other
      decorators in lines 4 and 5 specify how the parameters of the function should be mapped to the neuronal network. In this case, the
      parameters should be connected to two single neurons of the <i>actors</i> population through leaky integration,
      i.e. the parameters should hold the neurons current voltages. The first parameter <i>t</i> is always the current simulation
      time and cannot be remapped, whereas all other parameters can be mapped to both robot parts or neurons.</p>

    <p>The NRP platform calls these transfer functions at each simulation step, makes sure that they are called with the correct parameters and that
      the return value is handled correctly. The parameters may be connected to either the neuronal simulator through spike sources or spike sinks or to
      the robot through topic publishers or topic subscribers. These topic messages are then transmitted to the (simulated) robot currently through the
      Robot Operating System (ROS).</p>

    <h4>Current status</h4>

    <p>To further simplify the development of BIBI connections, we have designed an XML Schema capable to describe many transfer functions
      such as the one you have seen above. Since the XML format is formally defined by a Schema, such BIBI configurations may be created
      by various designers, including the graphical designer we are going to implement but also possibly designers by third-party vendors.
      Transfer functions can thus be specified either using the XML format or in Python and both kinds can be mixed in a single experiment.</p>

</div>
